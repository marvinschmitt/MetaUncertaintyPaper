{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment: SBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../BayesFlow')))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "from numba import njit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.tri as tri\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import gamma as gamma_fun\n",
    "import scipy.special as spec\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.networks import SequenceNet, EvidentialNetwork\n",
    "from bayesflow.trainers import ModelComparisonTrainer\n",
    "from bayesflow.models import GenerativeModel\n",
    "from bayesflow.amortizers import MultiModelAmortizer\n",
    "from bayesflow.diagnostics import plot_confusion_matrix, plot_calibration_curves, expected_calibration_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\" : 20,\n",
    "    \"xtick.labelsize\" : 16,\n",
    "    \"ytick.labelsize\" : 16,\n",
    "    #\"text.usetex\": True,\n",
    "    #\"font.family\": \"serif\",\n",
    "    #\"font.serif\": [\"times\"],\n",
    "    #'text.latex.preamble' : r'\\usepackage{{amsmath}}'\n",
    "})\n",
    "\n",
    "FILEFORMAT = 'pdf'\n",
    "DPI = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def xy2bc(xy, corners, midpoints, tol=1.e-3):\n",
    "    '''Converts 2D Cartesian coordinates to barycentric.'''\n",
    "    s = [(corners[i] - midpoints[i]).dot(xy - midpoints[i]) / 0.75 \\\n",
    "         for i in range(3)]\n",
    "    return np.clip(s, tol, 1.0 - tol)\n",
    "\n",
    "class Dirichlet:\n",
    "    def __init__(self, alpha):\n",
    "        from math import gamma\n",
    "        from operator import mul\n",
    "        self._alpha = np.array(alpha)\n",
    "        self._coef = gamma(np.sum(self._alpha)) / reduce(mul, [gamma(a) for a in self._alpha])\n",
    "    def pdf(self, x):\n",
    "        '''Returns pdf value for `x`.'''\n",
    "        from operator import mul\n",
    "        return self._coef * reduce(mul, [xx ** (aa - 1)\n",
    "                                         for (xx, aa)in zip(x, self._alpha)])\n",
    "    \n",
    "def draw_pdf_contours(dist, nlevels=200, subdiv=8, ax=None, f=None, **kwargs):\n",
    "    \n",
    "    \n",
    "    if ax is None and f is None:\n",
    "        f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    \n",
    "    corners = np.array([[0, 0], [1, 0], [0.5, 0.75**0.5]])\n",
    "    midpoints = [(corners[(i + 1) % 3] + corners[(i + 2) % 3]) / 2.0 \\\n",
    "             for i in range(3)]\n",
    "    triangle = tri.Triangulation(corners[:, 0], corners[:, 1])\n",
    "\n",
    "    refiner = tri.UniformTriRefiner(triangle)\n",
    "    trimesh = refiner.refine_triangulation(subdiv=subdiv)\n",
    "    pvals = [dist.pdf(xy2bc(xy, corners, midpoints)) for xy in zip(trimesh.x, trimesh.y)]\n",
    "\n",
    "    ax.tricontourf(trimesh, pvals, nlevels, **kwargs)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_viridis_palette(n, n_total=20, base_palette=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Builds a viridis palette with maximal entropy (evenly spaced)\n",
    "    \"\"\"\n",
    "    color_palette = np.array(sns.color_palette(base_palette, n_colors=n_total))\n",
    "    indices = np.array(np.floor(np.linspace(0, n_total-1, n)), dtype=np.int32)\n",
    "    color_palette = color_palette[indices]\n",
    "    return [tuple(c) for c in color_palette]\n",
    "\n",
    "color_codes = dict(zip([f\"M{i}\" for i in range(1, 5)], build_viridis_palette(5)[0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(color_codes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prior\n",
    "Implements sampling from $p(M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_prior(batch_size, n_models=3, p_vals=None):\n",
    "    \"\"\"\n",
    "    Samples from the models' prior batch size times and converts to one-hot.\n",
    "    Assumes equal model priors.\n",
    "    ----------\n",
    "\n",
    "    Arguments:\n",
    "    batch_size : int  -- the number of samples to draw from the prior\n",
    "    ----------\n",
    "\n",
    "    Returns:\n",
    "    m_true : np.ndarray of shape (batch_size, theta_dim) -- the samples batch of parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Equal priors, if nothign specified\n",
    "    if p_vals is None:\n",
    "        p_vals = [1 / n_models] * n_models\n",
    "    m_idx = np.random.choice(n_models, size=batch_size, p=p_vals).astype(np.int32)\n",
    "    return m_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter priors\n",
    "Implements sampling from each $p(\\theta_j\\,|\\,M_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     20,
     41
    ]
   },
   "outputs": [],
   "source": [
    "def model1_params_prior(**args):\n",
    "    \"\"\"\n",
    "    Samples from the prior of the HH-1pars theta = (gbar_Na)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "         np.random.uniform(low=1.5, high=30)    # gbar_Na\n",
    "    ]\n",
    "    return np.array(theta)\n",
    "\n",
    "def model2_params_prior(**args):\n",
    "    \"\"\"\n",
    "    Samples from the prior of the HH-2pars theta = (gbar_Na,gbar_K)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "         np.random.uniform(low=1.5, high=30),  # gbar_Na\n",
    "         np.random.uniform(low=0.3, high=15)   # gbar_K\n",
    "    ]\n",
    "    return np.array(theta)\n",
    "\n",
    "\n",
    "def model3_params_prior(**args):\n",
    "    \"\"\"\n",
    "     Samples from the prior of the HH-3pars theta = (gbar_Na,gbar_K,gbar_M)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "        np.random.uniform(low=1.5, high=30),   # gbar_Na\n",
    "        np.random.uniform(low=0.3, high=15),   # gbar_K\n",
    "        np.random.uniform(low=0.005, high=0.3) # gbar_M\n",
    "    ]\n",
    "    return np.array(theta)\n",
    "\n",
    "\n",
    "def model4_params_prior(**args):\n",
    "    \"\"\"\n",
    "    Samples from the prior of the HH-4pars theta = (gbar_l,gbar_Na,gbar_K,gbar_M)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "        np.random.uniform(low=0.01, high=0.18), # gbar_l\n",
    "        np.random.uniform(low=1.5, high=30),    # gbar_Na\n",
    "        np.random.uniform(low=0.3, high=15),    # gbar_K\n",
    "        np.random.uniform(low=0.005, high=0.3)  # gbar_M\n",
    "    ]\n",
    "    return np.array(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulators\n",
    "Implements each forward model (stochastic simulator) $g_j(\\theta_j,\\xi)$. Uses $numba$ for just-in-time compilation (i.e., speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#@njit\n",
    "def forward_model1(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    # HH-1pars\n",
    "\n",
    "    # pars = [gbar_Na]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "\n",
    "    I_duration = n_obs\n",
    "    gbar_Na = params\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2  # ms\n",
    "    Vt = -60.  # mV\n",
    "    nois_fact = 0.1  # uA/cm2\n",
    "    E_leak = -70.  # mV\n",
    "    E_Na = 53  # mV\n",
    "    E_K = -107  # mV\n",
    "    C = 1\n",
    "    g_l = 0.1\n",
    "    gbar_M = 0.07\n",
    "    gbar_K = 2.0 # fixed K\n",
    "\n",
    "    tstep = float(dt)\n",
    "\n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_post = 10\n",
    "    I_duration = np.round(n_obs * dt - t_on - t_post - dt, 2)\n",
    "    assert I_duration > 0, \"Please provide n_obs >= 106!\"\n",
    "    t_off = I_duration + t_post\n",
    "\n",
    "    t = np.arange(0, np.round(t_on + t_off + dt, 2), dt)\n",
    "\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on / dt)):int(np.round(t_off / dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z / 2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32 * efun(-0.25 * v1) / 0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28 * efun(0.2 * v1) / 0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128 * np.exp(-v1 / 18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0 / (1 + np.exp(-0.2 * v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032 * efun(-0.2 * v1) / 0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5 * np.exp(-v1 / 40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "        return 1 / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x) / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def tau_m(x):\n",
    "        return 1 / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x) / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def tau_h(x):\n",
    "        return 1 / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x) / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0 / (1. + np.exp(-0.1 * v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max / (3.3 * np.exp(0.05 * v1) + np.exp(-0.05 * v1))\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t)  # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] + (n[i - 1] ** 4) * gbar_K + g_l + gbar_M * p[i - 1]) / C\n",
    "        V_inf = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] * E_Na + (n[i - 1] ** 4) * gbar_K * E_K + g_l * E_leak + gbar_M *\n",
    "                 p[i - 1] * E_K\n",
    "                 + I[i - 1] + nois_fact * np.random.randn() / (tstep ** 0.5)) / (tau_V_inv * C)\n",
    "        V[i] = V_inf + (V[i - 1] - V_inf) * np.exp(-tstep * tau_V_inv)\n",
    "        n[i] = n_inf(V[i]) + (n[i - 1] - n_inf(V[i])) * np.exp(-tstep / tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i]) + (m[i - 1] - m_inf(V[i])) * np.exp(-tstep / tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i]) + (h[i - 1] - h_inf(V[i])) * np.exp(-tstep / tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i]) + (p[i - 1] - p_inf(V[i])) * np.exp(-tstep / tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)\n",
    "\n",
    "#@njit\n",
    "def forward_model2(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    # HH-2pars\n",
    "\n",
    "    # pars = [gbar_Na, gbar_K]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "\n",
    "    I_duration = n_obs\n",
    "    gbar_Na, gbar_K = params\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2  # ms\n",
    "    Vt = -60.  # mV\n",
    "    nois_fact = 0.1  # uA/cm2\n",
    "    E_leak = -70.  # mV\n",
    "    E_Na = 53  # mV\n",
    "    E_K = -107  # mV\n",
    "    C = 1\n",
    "    g_l = 0.1\n",
    "    gbar_M = 0.07\n",
    "\n",
    "    tstep = float(dt)\n",
    "\n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_post = 10\n",
    "    I_duration = np.round(n_obs * dt - t_on - t_post - dt, 2)\n",
    "    assert I_duration > 0, \"Please provide n_obs >= 106!\"\n",
    "    t_off = I_duration + t_post\n",
    "\n",
    "    t = np.arange(0, np.round(t_on + t_off + dt, 2), dt)\n",
    "\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on / dt)):int(np.round(t_off / dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z / 2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32 * efun(-0.25 * v1) / 0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28 * efun(0.2 * v1) / 0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128 * np.exp(-v1 / 18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0 / (1 + np.exp(-0.2 * v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032 * efun(-0.2 * v1) / 0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5 * np.exp(-v1 / 40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "        return 1 / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x) / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def tau_m(x):\n",
    "        return 1 / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x) / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def tau_h(x):\n",
    "        return 1 / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x) / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0 / (1. + np.exp(-0.1 * v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max / (3.3 * np.exp(0.05 * v1) + np.exp(-0.05 * v1))\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t)  # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] + (n[i - 1] ** 4) * gbar_K + g_l + gbar_M * p[i - 1]) / C\n",
    "        V_inf = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] * E_Na + (n[i - 1] ** 4) * gbar_K * E_K + g_l * E_leak + gbar_M *\n",
    "                 p[i - 1] * E_K\n",
    "                 + I[i - 1] + nois_fact * np.random.randn() / (tstep ** 0.5)) / (tau_V_inv * C)\n",
    "        V[i] = V_inf + (V[i - 1] - V_inf) * np.exp(-tstep * tau_V_inv)\n",
    "        n[i] = n_inf(V[i]) + (n[i - 1] - n_inf(V[i])) * np.exp(-tstep / tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i]) + (m[i - 1] - m_inf(V[i])) * np.exp(-tstep / tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i]) + (h[i - 1] - h_inf(V[i])) * np.exp(-tstep / tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i]) + (p[i - 1] - p_inf(V[i])) * np.exp(-tstep / tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)\n",
    "\n",
    "\n",
    "#@njit\n",
    "def forward_model3(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    # HH-3pars\n",
    "\n",
    "    # pars = [gbar_Na, gbar_K, gbar_M]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "\n",
    "    I_duration = n_obs\n",
    "    gbar_Na, gbar_K, gbar_M = params\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2  # ms\n",
    "    Vt = -60.  # mV\n",
    "    nois_fact = 0.1  # uA/cm2\n",
    "    E_leak = -70.  # mV\n",
    "    E_Na = 53  # mV\n",
    "    E_K = -107  # mV\n",
    "    C = 1\n",
    "    g_l = 0.1\n",
    "\n",
    "    tstep = float(dt)\n",
    "\n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_post = 10\n",
    "    I_duration = np.round(n_obs * dt - t_on - t_post - dt, 2)\n",
    "    assert I_duration > 0, \"Please provide n_obs >= 106!\"\n",
    "    t_off = I_duration + t_post\n",
    "\n",
    "    t = np.arange(0, np.round(t_on + t_off + dt, 2), dt)\n",
    "\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on / dt)):int(np.round(t_off / dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z / 2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32 * efun(-0.25 * v1) / 0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28 * efun(0.2 * v1) / 0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128 * np.exp(-v1 / 18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0 / (1 + np.exp(-0.2 * v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032 * efun(-0.2 * v1) / 0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5 * np.exp(-v1 / 40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "        return 1 / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x) / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def tau_m(x):\n",
    "        return 1 / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x) / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def tau_h(x):\n",
    "        return 1 / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x) / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0 / (1. + np.exp(-0.1 * v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max / (3.3 * np.exp(0.05 * v1) + np.exp(-0.05 * v1))\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t)  # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] + (n[i - 1] ** 4) * gbar_K + g_l + gbar_M * p[i - 1]) / C\n",
    "        V_inf = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] * E_Na + (n[i - 1] ** 4) * gbar_K * E_K + g_l * E_leak + gbar_M *\n",
    "                 p[i - 1] * E_K\n",
    "                 + I[i - 1] + nois_fact * np.random.randn() / (tstep ** 0.5)) / (tau_V_inv * C)\n",
    "        V[i] = V_inf + (V[i - 1] - V_inf) * np.exp(-tstep * tau_V_inv)\n",
    "        n[i] = n_inf(V[i]) + (n[i - 1] - n_inf(V[i])) * np.exp(-tstep / tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i]) + (m[i - 1] - m_inf(V[i])) * np.exp(-tstep / tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i]) + (h[i - 1] - h_inf(V[i])) * np.exp(-tstep / tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i]) + (p[i - 1] - p_inf(V[i])) * np.exp(-tstep / tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)\n",
    "\n",
    "\n",
    "#@njit\n",
    "def forward_model4(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    # HH-4pars\n",
    "\n",
    "    # pars = [gbar_l, gbar_Na, gbar_K, gbar_M]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "\n",
    "    I_duration = n_obs\n",
    "    g_l, gbar_Na, gbar_K, gbar_M = params\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2  # ms\n",
    "    Vt = -60.  # mV\n",
    "    nois_fact = 0.1  # uA/cm2\n",
    "    E_leak = -70.  # mV\n",
    "    E_Na = 53  # mV\n",
    "    E_K = -107  # mV\n",
    "    C = 1\n",
    "\n",
    "    tstep = float(dt)\n",
    "\n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_post = 10\n",
    "    I_duration = np.round(n_obs * dt - t_on - t_post - dt, 2)\n",
    "    assert I_duration > 0, \"Please provide n_obs >= 106!\"\n",
    "    t_off = I_duration + t_post\n",
    "\n",
    "    t = np.arange(0, np.round(t_on + t_off + dt, 2), dt)\n",
    "\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on / dt)):int(np.round(t_off / dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z / 2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32 * efun(-0.25 * v1) / 0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28 * efun(0.2 * v1) / 0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128 * np.exp(-v1 / 18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0 / (1 + np.exp(-0.2 * v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032 * efun(-0.2 * v1) / 0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5 * np.exp(-v1 / 40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "        return 1 / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x) / (alpha_n(x) + beta_n(x))\n",
    "\n",
    "    def tau_m(x):\n",
    "        return 1 / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x) / (alpha_m(x) + beta_m(x))\n",
    "\n",
    "    def tau_h(x):\n",
    "        return 1 / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x) / (alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0 / (1. + np.exp(-0.1 * v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max / (3.3 * np.exp(0.05 * v1) + np.exp(-0.05 * v1))\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t)  # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] + (n[i - 1] ** 4) * gbar_K + g_l + gbar_M * p[i - 1]) / C\n",
    "        V_inf = ((m[i - 1] ** 3) * gbar_Na * h[i - 1] * E_Na + (n[i - 1] ** 4) * gbar_K * E_K + g_l * E_leak + gbar_M *\n",
    "                 p[i - 1] * E_K\n",
    "                 + I[i - 1] + nois_fact * np.random.randn() / (tstep ** 0.5)) / (tau_V_inv * C)\n",
    "        V[i] = V_inf + (V[i - 1] - V_inf) * np.exp(-tstep * tau_V_inv)\n",
    "        n[i] = n_inf(V[i]) + (n[i - 1] - n_inf(V[i])) * np.exp(-tstep / tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i]) + (m[i - 1] - m_inf(V[i])) * np.exp(-tstep / tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i]) + (h[i - 1] - h_inf(V[i])) * np.exp(-tstep / tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i]) + (p[i - 1] - p_inf(V[i])) * np.exp(-tstep / tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example amortized model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your prior predictive checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an amortized estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidential_meta = {\n",
    "    'n_models': 3,\n",
    "    'out_activation': 'softplus',\n",
    "    'n_dense': 3,\n",
    "    'dense_args': {'kernel_initializer': 'glorot_uniform', 'activation': 'relu', 'units': 128}\n",
    "}\n",
    "evidential_net = EvidentialNetwork(evidential_meta)\n",
    "\n",
    "summary_net = SequenceNet()\n",
    "\n",
    "\n",
    "amortizer = MultiModelAmortizer(evidential_net, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [model2_params_prior, model3_params_prior, model4_params_prior]\n",
    "simulators = [forward_model2, forward_model3, forward_model4]\n",
    "generative_model = GenerativeModel(model_prior, priors, simulators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelComparisonTrainer(amortizer, \n",
    "                                 generative_model, \n",
    "                                 learning_rate=lr_schedule,\n",
    "                                 skip_checks=True,\n",
    "                                 checkpoint_path=f'checkpoint_exp3',\n",
    "                                 max_to_keep=1\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round-based training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses = trainer.train_online(epochs=50, iterations_per_epoch=500, batch_size=16, n_obs=1101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "params_1 = np.array([3])\n",
    "params_2 = np.array([3, 2])\n",
    "params_3 = np.array([3, 2, 0.1])\n",
    "\n",
    "t = np.linspace(0, 400, 1051)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(12, 8))\n",
    "for _ in range(10):\n",
    "    x1 = forward_model1(params_1, n_obs=1101)\n",
    "    x2 = forward_model2(params_2, n_obs=1101)\n",
    "    x3 = forward_model3(params_3, n_obs=1101)\n",
    "    ax[0].plot(t, x1[50:], label=r'$M_1$', alpha=0.5, lw=1.5, color=color_codes[\"M1\"])\n",
    "    ax[1].plot(t, x2[50:], label=r'$M_2$', alpha=0.5, lw=1.5, color=color_codes[\"M2\"])\n",
    "    ax[2].plot(t, x3[50:], label=r'$M_3$', alpha=0.5, lw=1.5, color=color_codes[\"M3\"])\n",
    "    \n",
    "for i in range(3):\n",
    "    ax[i].spines['right'].set_visible(False)\n",
    "    ax[i].spines['top'].set_visible(False)\n",
    "    ax[i].set_ylabel(r'Voltage ($\\mu V$)', fontsize=14)\n",
    "    ax[i].set_xlim([0, 400])\n",
    "    \n",
    "ax[2].set_xlabel(r'Time step ($t$)', fontsize=14)\n",
    "f.tight_layout()\n",
    "\n",
    "plt.gcf().text(-0.03, 0.8, r'$M_1$', fontsize=24)\n",
    "plt.gcf().text(-0.03, 0.5, r'$M_2$', fontsize=24)\n",
    "plt.gcf().text(-0.03, 0.2, r'$M_3$', fontsize=24)\n",
    "\n",
    "f.savefig('../output/plots/experiment-3-HH_forward_model.pdf', dpi=300, bbox_inches='tight')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x1 = tf.convert_to_tensor(\n",
    "                        forward_model3(np.array([4., 0.5, 0.15]), n_obs=1101)[np.newaxis, :], dtype=tf.float32\n",
    "                    )\n",
    "\n",
    "for i, x in enumerate([x1], start=1):\n",
    "    alpha = trainer.network(x).numpy().flatten()\n",
    "    plt.clf()\n",
    "    plt.plot(x.numpy()[0, :, 0], color='#871414', lw=2)\n",
    "    plt.savefig(f\"../output/plots/experiment-3-x-{i}.pdf\", dpi=300)\n",
    "    \n",
    "    plt.clf()\n",
    "    d_samples = stats.dirichlet.rvs(alpha, size=3000)\n",
    "    colors = (color_codes[\"M1\"], color_codes[\"M2\"], color_codes[\"M3\"])\n",
    "    parts = plt.violinplot(d_samples, [0, 1, 2], showmedians=True)\n",
    "    for c, pc in zip(colors, parts['bodies']):\n",
    "        pc.set_facecolor(c)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.8)\n",
    "\n",
    "    for partname in ('cbars','cmins','cmaxes', 'cmedians'):\n",
    "        vp = parts[partname]\n",
    "        vp.set_edgecolor('black')\n",
    "        vp.set_linewidth(2)\n",
    "\n",
    "    #plt.spines['right'].set_visible(False)\n",
    "    #plt.spines['top'].set_visible(False)\n",
    "    plt.xticks(ticks=[0,1, 2], labels=[r'$M_1$', r'$M_2$', r'$M_3$'])\n",
    "    plt.yticks(ticks=[0.0, 0.5, 1.0], labels=[0.0, 0.5, 1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "    plt.savefig(f\"../output/plots/experiment-3-pmp_violinplot-{i}.pdf\", dpi=300)\n",
    "    \n",
    "    np.savetxt(f\"../output/computations/experiment-3-alpha-{i}.csv\", alpha, delimiter=\",\", fmt='%10.5f', header='Header')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMPs from simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 200\n",
    "\n",
    "true_model, theta, x_sim = trainer.generative_model(n_sim=n_simulations, n_obs=1101)\n",
    "\n",
    "alpha = trainer.network(x_sim).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "{\n",
    "    'idx': np.arange(1, n_simulations+1),\n",
    "    'true_model': np.argmax(true_model, axis=1) + 1,\n",
    "    'alpha_1': alpha[:, 0],\n",
    "    'alpha_2': alpha[:, 1],\n",
    "    'alpha_3': alpha[:, 2]\n",
    "}\n",
    ")\n",
    "df.to_csv(\"../output/computations/experiment-3-simulated-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
